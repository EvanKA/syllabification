{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Syllable - Joseph Jojoe","metadata":{"id":"CaKQj5AVhKR_"}},{"cell_type":"code","source":"","metadata":{"id":"pUgwfh0oKjss","outputId":"385f269c-7fb7-4da7-b7e5-766a8f8f530c","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Imports dependencies\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport tensorflow_addons as tfa\nfrom tensorflow.keras import regularizers\nfrom keras.models import Model\nimport pathlib\nimport os\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nimport string\nimport random\nfrom keras.preprocessing.text import Tokenizer","metadata":{"id":"csu57YRLhUPe","execution":{"iopub.status.busy":"2021-12-02T01:05:56.611950Z","iopub.execute_input":"2021-12-02T01:05:56.612715Z","iopub.status.idle":"2021-12-02T01:05:56.618880Z","shell.execute_reply.started":"2021-12-02T01:05:56.612678Z","shell.execute_reply":"2021-12-02T01:05:56.618166Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"YmQuy8YpDbCg","outputId":"43f470b5-d3b8-4b35-e1c3-9c72e64444bd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Loads in syllable data\ndataframe = pd.read_csv(\"../input/nlpsyllable/preprocessed.txt\",\n                        sep=\",\",\n                        encoding=\"ISO-8859-1\",\n                        names=[\"word\", \"label\"])\n# Necessary to specify str type for pandas columns\ndataframe = dataframe.astype(str)\nwords = dataframe['word'].tolist()\nlabels = dataframe['label'].tolist()\n# Converts each label to numpy array\nfor i in range(0, len(labels)):\n    labels[i] = list(labels[i])\n    for j in range(0, len(labels[i])):\n        labels[i][j] = int(labels[i][j])\nfor i in range(0, len(labels)):\n    labels[i] = np.array(labels[i])","metadata":{"id":"vjbfSUbohytB","execution":{"iopub.status.busy":"2021-12-02T01:05:56.620469Z","iopub.execute_input":"2021-12-02T01:05:56.620946Z","iopub.status.idle":"2021-12-02T01:05:59.018282Z","shell.execute_reply.started":"2021-12-02T01:05:56.620879Z","shell.execute_reply":"2021-12-02T01:05:59.017304Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# Vectorises syllable strings by treating each character as a token\ntokenizer = Tokenizer(char_level=True)\ntokenizer.fit_on_texts(words)\nwords = tokenizer.texts_to_sequences(words)\nfor i in range(0, len(words)):\n    words[i] = np.array(words[i], dtype=float)\n\npadded_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n    words, padding=\"post\", maxlen=15\n)\npadded_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n    labels, padding=\"post\", maxlen=15\n)\n\n# Normalisation\nmaximum_token = 64\nfor element in range(0, len(words)):\n    words[element] = words[element] / maximum_token","metadata":{"id":"6gDS7CtLiAIj","execution":{"iopub.status.busy":"2021-12-02T01:05:59.019978Z","iopub.execute_input":"2021-12-02T01:05:59.020248Z","iopub.status.idle":"2021-12-02T01:06:02.996218Z","shell.execute_reply.started":"2021-12-02T01:05:59.020211Z","shell.execute_reply":"2021-12-02T01:06:02.995488Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# shuffles data\nseed = random.random()\nrandom.seed(seed)\nrandom.shuffle(padded_inputs)\nrandom.seed(seed)\nrandom.shuffle(padded_outputs)\n\n# splits into training and validation sets (80-20 split)\nvalidation_inputs = padded_inputs[-35497:]\nvalidation_outputs = padded_outputs[-35497:]\npadded_inputs = padded_inputs[:-35497]\npadded_outputs = padded_outputs[:-35497]","metadata":{"id":"jgZKQGe1iFpj","execution":{"iopub.status.busy":"2021-12-02T01:06:02.997578Z","iopub.execute_input":"2021-12-02T01:06:02.997820Z","iopub.status.idle":"2021-12-02T01:06:03.876072Z","shell.execute_reply.started":"2021-12-02T01:06:02.997787Z","shell.execute_reply":"2021-12-02T01:06:03.875215Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"# Custom loss function - mean of binary crossentropy and mean squared error\ndef mean_weighted_bce_mse(y_true, y_prediction):\n    y_true = tf.cast(y_true, tf.float32)\n    y_prediction = tf.cast(y_prediction, tf.float32)\n\n    # Binary crossentropy with weighting\n    epsilon = 1e-6\n    positive_weight = 4.108897148948174\n    loss_positive = y_true * tf.math.log(y_prediction + epsilon)\n    loss_negative = (1 - y_true) * tf.math.log(1 - y_prediction + epsilon)\n    bce_loss = tf.math.reduce_mean(tf.math.negative(positive_weight * loss_positive + loss_negative))\n    \n    # Mean squared error\n    mse = tf.keras.losses.MeanSquaredError()\n    mse_loss = mse(y_true, y_prediction)\n\n    averaged_bce_mse = (bce_loss + mse_loss) / 2\n    return averaged_bce_mse","metadata":{"id":"YQezB-7cRHOC","execution":{"iopub.status.busy":"2021-12-02T01:06:03.878485Z","iopub.execute_input":"2021-12-02T01:06:03.878793Z","iopub.status.idle":"2021-12-02T01:06:03.885503Z","shell.execute_reply.started":"2021-12-02T01:06:03.878752Z","shell.execute_reply":"2021-12-02T01:06:03.884581Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"def inception_module(inputs):\n    inception_branch_1 = tf.keras.layers.Conv1D(128, kernel_size=1, strides=2, activation=\"tanh\", activity_regularizer=tf.keras.regularizers.l2(1e-5))(inputs)\n    inception_branch_1 = tf.keras.layers.ZeroPadding1D(padding=(0, 15 - inception_branch_1.shape[1]))(inception_branch_1)\n\n    inception_branch_2 = tf.keras.layers.Conv1D(128, kernel_size=1, activation=\"tanh\", activity_regularizer=tf.keras.regularizers.l2(1e-5))(inputs)\n    inception_branch_2 = tf.keras.layers.Conv1D(128, kernel_size=3, strides=2, activation=\"tanh\", activity_regularizer=tf.keras.regularizers.l2(1e-5))(inception_branch_2)\n    inception_branch_2 = tf.keras.layers.ZeroPadding1D(padding=(0, 15 - inception_branch_2.shape[1]))(inception_branch_2)\n\n    inception_branch_3 = tf.keras.layers.AveragePooling1D(pool_size=3, strides=2)(inputs)\n    inception_branch_3 = tf.keras.layers.Conv1D(128, kernel_size=3, activation=\"tanh\", activity_regularizer=tf.keras.regularizers.l2(1e-5))(inception_branch_3)\n    inception_branch_3 = tf.keras.layers.ZeroPadding1D(padding=(0, 15 - inception_branch_3.shape[1]))(inception_branch_3)\n\n    inception_branch_4 = tf.keras.layers.Conv1D(128, kernel_size=1, activation=\"tanh\", activity_regularizer=tf.keras.regularizers.l2(1e-5))(inputs)\n    inception_branch_4 = tf.keras.layers.Conv1D(128, kernel_size=3, activation=\"tanh\", activity_regularizer=tf.keras.regularizers.l2(1e-5))(inception_branch_4)\n    inception_branch_4 = tf.keras.layers.Conv1D(128, kernel_size=3, strides=2, activation=\"tanh\", activity_regularizer=tf.keras.regularizers.l2(1e-5))(inception_branch_4)\n    inception_branch_4 = tf.keras.layers.ZeroPadding1D(padding=(0, 15 - inception_branch_4.shape[1]))(inception_branch_4)\n\n    inception_output = tf.keras.layers.concatenate([inception_branch_1, inception_branch_2, inception_branch_3, inception_branch_4, inputs])\n    return inception_output","metadata":{"id":"Df2UpqpKl16x","execution":{"iopub.status.busy":"2021-12-02T01:06:03.887178Z","iopub.execute_input":"2021-12-02T01:06:03.887876Z","iopub.status.idle":"2021-12-02T01:06:03.902846Z","shell.execute_reply.started":"2021-12-02T01:06:03.887791Z","shell.execute_reply":"2021-12-02T01:06:03.901950Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"inputs = tf.keras.Input(shape=(15,))\nembedded_inputs = tf.keras.layers.Embedding(64, 256, mask_zero=True)(inputs)\nembedded_inputs = tf.keras.layers.Dropout(0.25)(embedded_inputs)\n\nx = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(256, return_sequences=True, dropout=0.1, activity_regularizer=tf.keras.regularizers.l2(1e-5)))(embedded_inputs)\nx = tf.keras.layers.concatenate([x, embedded_inputs])\nx = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(256, return_sequences=True, dropout=0.1, activity_regularizer=tf.keras.regularizers.l2(1e-5)))(x)\nx = tf.keras.layers.concatenate([x, embedded_inputs])\nx = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(256, return_sequences=True, activity_regularizer=tf.keras.regularizers.l2(1e-5)))(x)\n\ninception_output = inception_module(embedded_inputs)\ninception_output = tf.keras.layers.MaxPooling1D()(inception_output)\ninception_output =  tf.keras.layers.ZeroPadding1D(padding=(0, 15 - inception_output.shape[1]))(inception_output)\ninception_output = tf.keras.layers.Dropout(0.5)(inception_output)\ninception_output = inception_module(inception_output)\ninception_output = tf.keras.layers.MaxPooling1D()(inception_output)\ninception_output =  tf.keras.layers.ZeroPadding1D(padding=(0, 15 - inception_output.shape[1]))(inception_output)\n\noutput = tf.keras.layers.concatenate([x, inception_output, embedded_inputs])\noutput = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(256, activation=\"relu\"))(output)\noutput = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(64, activation=\"relu\"))(output)\noutput = tf.keras.layers.GlobalMaxPool1D()(output)\noutput = tf.keras.layers.Dense(15, activation=\"sigmoid\")(output)\n\nmetrics = [\"binary_accuracy\",\n           tfa.metrics.F1Score(num_classes=15, threshold=0.5),\n           tfa.metrics.HammingLoss(mode='multilabel', threshold=0.5),\n           tf.keras.metrics.Recall(),\n           tf.keras.metrics.Precision(),\n           tf.keras.metrics.AUC(multi_label=True, num_labels=15)]\n\nmodel = tf.keras.models.Model(inputs=inputs, outputs=output)\nmodel.compile(optimizer=\"adam\",\n              loss=mean_weighted_bce_mse,\n              metrics=metrics,\n              steps_per_execution=128)","metadata":{"id":"EOip602ziQok","execution":{"iopub.status.busy":"2021-12-02T01:06:03.905699Z","iopub.execute_input":"2021-12-02T01:06:03.905908Z","iopub.status.idle":"2021-12-02T01:06:08.830190Z","shell.execute_reply.started":"2021-12-02T01:06:03.905870Z","shell.execute_reply":"2021-12-02T01:06:08.829429Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"id":"rM_seEmJg7ux","outputId":"a74d6e33-ebcd-4fb3-c473-861ebd635e47","execution":{"iopub.status.busy":"2021-12-02T01:06:08.831575Z","iopub.execute_input":"2021-12-02T01:06:08.831805Z","iopub.status.idle":"2021-12-02T01:06:08.857107Z","shell.execute_reply.started":"2021-12-02T01:06:08.831775Z","shell.execute_reply":"2021-12-02T01:06:08.856427Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"history = model.fit(padded_inputs,\n                    padded_outputs,\n                    validation_data=(validation_inputs, validation_outputs),\n                    epochs=100,\n                    batch_size=256)","metadata":{"id":"5_CQt-B_ibtm","outputId":"b829ab16-240f-4508-a3d7-0d723710bb0c","execution":{"iopub.status.busy":"2021-12-02T01:06:08.858214Z","iopub.execute_input":"2021-12-02T01:06:08.858452Z","iopub.status.idle":"2021-12-02T02:08:06.031714Z","shell.execute_reply.started":"2021-12-02T01:06:08.858419Z","shell.execute_reply":"2021-12-02T02:08:06.030928Z"},"trusted":true},"execution_count":32,"outputs":[]}]}