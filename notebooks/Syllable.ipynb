{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Syllable - Joseph Jojoe","metadata":{"id":"CaKQj5AVhKR_"}},{"cell_type":"code","source":"","metadata":{"id":"pUgwfh0oKjss","outputId":"385f269c-7fb7-4da7-b7e5-766a8f8f530c","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Imports dependencies\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport tensorflow_addons as tfa\nfrom tensorflow.keras import regularizers\nfrom keras.models import Model\nimport pathlib\nimport os\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nimport string\nimport random\nfrom keras.preprocessing.text import Tokenizer","metadata":{"id":"csu57YRLhUPe","execution":{"iopub.status.busy":"2021-12-01T23:55:17.468679Z","iopub.execute_input":"2021-12-01T23:55:17.469490Z","iopub.status.idle":"2021-12-01T23:55:17.475599Z","shell.execute_reply.started":"2021-12-01T23:55:17.469444Z","shell.execute_reply":"2021-12-01T23:55:17.474758Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"YmQuy8YpDbCg","outputId":"43f470b5-d3b8-4b35-e1c3-9c72e64444bd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Loads in syllable data\ndataframe = pd.read_csv(\"../input/nlpsyllable/preprocessed.txt\",\n                        sep=\",\",\n                        encoding=\"ISO-8859-1\",\n                        names=[\"word\", \"label\"])\n# Necessary to specify str type for pandas columns\ndataframe = dataframe.astype(str)\nwords = dataframe['word'].tolist()\nlabels = dataframe['label'].tolist()\n# Converts each label to numpy array\nfor i in range(0, len(labels)):\n    labels[i] = list(labels[i])\n    for j in range(0, len(labels[i])):\n        labels[i][j] = int(labels[i][j])\nfor i in range(0, len(labels)):\n    labels[i] = np.array(labels[i])","metadata":{"id":"vjbfSUbohytB","execution":{"iopub.status.busy":"2021-12-01T23:55:17.476793Z","iopub.execute_input":"2021-12-01T23:55:17.480279Z","iopub.status.idle":"2021-12-01T23:55:19.768676Z","shell.execute_reply.started":"2021-12-01T23:55:17.480236Z","shell.execute_reply":"2021-12-01T23:55:19.767885Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# Vectorises syllable strings by treating each character as a token\ntokenizer = Tokenizer(char_level=True)\ntokenizer.fit_on_texts(words)\nwords = tokenizer.texts_to_sequences(words)\nfor i in range(0, len(words)):\n    words[i] = np.array(words[i], dtype=float)\n\npadded_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n    words, padding=\"post\", maxlen=15\n)\npadded_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n    labels, padding=\"post\", maxlen=15\n)\n\n# Normalisation\nmaximum_token = 64\nfor element in range(0, len(words)):\n    words[element] = words[element] / maximum_token","metadata":{"id":"6gDS7CtLiAIj","execution":{"iopub.status.busy":"2021-12-01T23:55:19.770570Z","iopub.execute_input":"2021-12-01T23:55:19.770870Z","iopub.status.idle":"2021-12-01T23:55:23.479675Z","shell.execute_reply.started":"2021-12-01T23:55:19.770831Z","shell.execute_reply":"2021-12-01T23:55:23.478948Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# shuffles data\nseed = random.random()\nrandom.seed(seed)\nrandom.shuffle(padded_inputs)\nrandom.seed(seed)\nrandom.shuffle(padded_outputs)\n\n# splits into training and validation sets (80-20 split)\nvalidation_inputs = padded_inputs[-35497:]\nvalidation_outputs = padded_outputs[-35497:]\npadded_inputs = padded_inputs[:-35497]\npadded_outputs = padded_outputs[:-35497]","metadata":{"id":"jgZKQGe1iFpj","execution":{"iopub.status.busy":"2021-12-01T23:55:23.480953Z","iopub.execute_input":"2021-12-01T23:55:23.481186Z","iopub.status.idle":"2021-12-01T23:55:24.361417Z","shell.execute_reply.started":"2021-12-01T23:55:23.481154Z","shell.execute_reply":"2021-12-01T23:55:24.360686Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# Custom loss function - mean of binary crossentropy and mean squared error\ndef mean_weighted_bce_mse(y_true, y_prediction):\n    y_true = tf.cast(y_true, tf.float32)\n    y_prediction = tf.cast(y_prediction, tf.float32)\n\n    # Binary crossentropy with weighting\n    epsilon = 1e-6\n    positive_weight = 4.108897148948174\n    loss_positive = y_true * tf.math.log(y_prediction + epsilon)\n    loss_negative = (1 - y_true) * tf.math.log(1 - y_prediction + epsilon)\n    bce_loss = tf.math.reduce_mean(tf.math.negative(positive_weight * loss_positive + loss_negative))\n    \n    # Mean squared error\n    mse = tf.keras.losses.MeanSquaredError()\n    mse_loss = mse(y_true, y_prediction)\n\n    averaged_bce_mse = (bce_loss + mse_loss) / 2\n    return averaged_bce_mse","metadata":{"id":"YQezB-7cRHOC","execution":{"iopub.status.busy":"2021-12-01T23:55:24.363807Z","iopub.execute_input":"2021-12-01T23:55:24.364084Z","iopub.status.idle":"2021-12-01T23:55:24.370598Z","shell.execute_reply.started":"2021-12-01T23:55:24.364047Z","shell.execute_reply":"2021-12-01T23:55:24.369853Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"def inception_module(inputs):\n    inception_branch_1 = tf.keras.layers.Conv1D(128, kernel_size=1, strides=2, activation=\"tanh\", activity_regularizer=tf.keras.regularizers.l2(1e-5))(inputs)\n    inception_branch_1 = tf.keras.layers.ZeroPadding1D(padding=(0, 15 - inception_branch_1.shape[1]))(inception_branch_1)\n\n    inception_branch_2 = tf.keras.layers.Conv1D(128, kernel_size=1, activation=\"tanh\", activity_regularizer=tf.keras.regularizers.l2(1e-5))(inputs)\n    inception_branch_2 = tf.keras.layers.Conv1D(128, kernel_size=3, strides=2, activation=\"tanh\", activity_regularizer=tf.keras.regularizers.l2(1e-5))(inception_branch_2)\n    inception_branch_2 = tf.keras.layers.ZeroPadding1D(padding=(0, 15 - inception_branch_2.shape[1]))(inception_branch_2)\n\n    inception_branch_3 = tf.keras.layers.AveragePooling1D(pool_size=3, strides=2)(inputs)\n    inception_branch_3 = tf.keras.layers.Conv1D(128, kernel_size=3, activation=\"tanh\", activity_regularizer=tf.keras.regularizers.l2(1e-5))(inception_branch_3)\n    inception_branch_3 = tf.keras.layers.ZeroPadding1D(padding=(0, 15 - inception_branch_3.shape[1]))(inception_branch_3)\n\n    inception_branch_4 = tf.keras.layers.Conv1D(128, kernel_size=1, activation=\"tanh\", activity_regularizer=tf.keras.regularizers.l2(1e-5))(inputs)\n    inception_branch_4 = tf.keras.layers.Conv1D(128, kernel_size=3, activation=\"tanh\", activity_regularizer=tf.keras.regularizers.l2(1e-5))(inception_branch_4)\n    inception_branch_4 = tf.keras.layers.Conv1D(128, kernel_size=3, strides=2, activation=\"tanh\", activity_regularizer=tf.keras.regularizers.l2(1e-5))(inception_branch_4)\n    inception_branch_4 = tf.keras.layers.ZeroPadding1D(padding=(0, 15 - inception_branch_4.shape[1]))(inception_branch_4)\n\n    inception_output = tf.keras.layers.concatenate([inception_branch_1, inception_branch_2, inception_branch_3, inception_branch_4, inputs])\n    return inception_output","metadata":{"id":"Df2UpqpKl16x","execution":{"iopub.status.busy":"2021-12-01T23:55:24.372992Z","iopub.execute_input":"2021-12-01T23:55:24.373536Z","iopub.status.idle":"2021-12-01T23:55:24.386841Z","shell.execute_reply.started":"2021-12-01T23:55:24.373499Z","shell.execute_reply":"2021-12-01T23:55:24.386083Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"inputs = tf.keras.Input(shape=(15,))\nembedded_inputs = tf.keras.layers.Embedding(64, 256, mask_zero=True)(inputs)\nembedded_inputs = tf.keras.layers.Dropout(0.25)(embedded_inputs)\n\nx = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(256, return_sequences=True, dropout=0.1, activity_regularizer=tf.keras.regularizers.l2(1e-5)))(embedded_inputs)\nx = tf.keras.layers.concatenate([x, embedded_inputs])\nx = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(256, return_sequences=True, dropout=0.1, activity_regularizer=tf.keras.regularizers.l2(1e-5)))(x)\nx = tf.keras.layers.concatenate([x, embedded_inputs])\nx = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(256, return_sequences=True, activity_regularizer=tf.keras.regularizers.l2(1e-5)))(x)\n\ninception_output = inception_module(embedded_inputs)\ninception_output = tf.keras.layers.MaxPooling1D()(inception_output)\ninception_output =  tf.keras.layers.ZeroPadding1D(padding=(0, 15 - inception_output.shape[1]))(inception_output)\ninception_output = tf.keras.layers.Dropout(0.5)(inception_output)\ninception_output = inception_module(inception_output)\ninception_output = tf.keras.layers.MaxPooling1D()(inception_output)\ninception_output =  tf.keras.layers.ZeroPadding1D(padding=(0, 15 - inception_output.shape[1]))(inception_output)\n\noutput = tf.keras.layers.concatenate([x, inception_output, embedded_inputs])\noutput = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(256, activation=\"relu\"))(output)\noutput = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(64, activation=\"relu\"))(output)\noutput = tf.keras.layers.GlobalMaxPool1D()(output)\noutput = tf.keras.layers.Dense(15, activation=\"sigmoid\")(output)\n\nmetrics = [\"binary_accuracy\",\n           tfa.metrics.F1Score(num_classes=15, threshold=0.5),\n           tfa.metrics.HammingLoss(mode='multilabel', threshold=0.5),\n           tf.keras.metrics.Recall(),\n           tf.keras.metrics.Precision(),\n           tf.keras.metrics.AUC(multi_label=True, num_labels=15)]\n\nmodel = tf.keras.models.Model(inputs=inputs, outputs=output)\nmodel.compile(optimizer=\"adam\",\n              loss=mean_weighted_bce_mse,\n              metrics=metrics,\n              steps_per_execution=128)","metadata":{"id":"EOip602ziQok","execution":{"iopub.status.busy":"2021-12-01T23:55:24.388120Z","iopub.execute_input":"2021-12-01T23:55:24.388526Z","iopub.status.idle":"2021-12-01T23:55:29.003826Z","shell.execute_reply.started":"2021-12-01T23:55:24.388489Z","shell.execute_reply":"2021-12-01T23:55:29.003110Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"id":"rM_seEmJg7ux","outputId":"a74d6e33-ebcd-4fb3-c473-861ebd635e47","execution":{"iopub.status.busy":"2021-12-01T23:55:29.005083Z","iopub.execute_input":"2021-12-01T23:55:29.005318Z","iopub.status.idle":"2021-12-01T23:55:29.030866Z","shell.execute_reply.started":"2021-12-01T23:55:29.005287Z","shell.execute_reply":"2021-12-01T23:55:29.030219Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"history = model.fit(padded_inputs,\n                    padded_outputs,\n                    validation_data=(validation_inputs, validation_outputs),\n                    epochs=60,\n                    batch_size=128)","metadata":{"id":"5_CQt-B_ibtm","outputId":"b829ab16-240f-4508-a3d7-0d723710bb0c","execution":{"iopub.status.busy":"2021-12-01T23:55:29.033523Z","iopub.execute_input":"2021-12-01T23:55:29.033713Z","iopub.status.idle":"2021-12-02T01:03:27.123157Z","shell.execute_reply.started":"2021-12-01T23:55:29.033689Z","shell.execute_reply":"2021-12-02T01:03:27.122320Z"},"trusted":true},"execution_count":23,"outputs":[]}]}