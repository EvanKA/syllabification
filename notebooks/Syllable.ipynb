{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Syllable.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CaKQj5AVhKR_"
      },
      "source": [
        "Syllable - Joseph Jojoe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUgwfh0oKjss",
        "outputId": "385f269c-7fb7-4da7-b7e5-766a8f8f530c"
      },
      "source": [
        "!pip install tensorflow_addons"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow_addons\n",
            "  Downloading tensorflow_addons-0.15.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[?25l\r\u001b[K     |▎                               | 10 kB 20.9 MB/s eta 0:00:01\r\u001b[K     |▋                               | 20 kB 26.5 MB/s eta 0:00:01\r\u001b[K     |▉                               | 30 kB 23.5 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 40 kB 18.5 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 51 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 61 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |██                              | 71 kB 11.7 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 81 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 92 kB 13.8 MB/s eta 0:00:01\r\u001b[K     |███                             | 102 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 112 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 122 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 133 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 143 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 153 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 163 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |█████                           | 174 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 184 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 194 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 204 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 215 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 225 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 235 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |███████                         | 245 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 256 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 266 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |████████                        | 276 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 286 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 296 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 307 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 317 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 327 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 337 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 348 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 358 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 368 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 378 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 389 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 399 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 409 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 419 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 430 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 440 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 450 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 460 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 471 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 481 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 491 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 501 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 512 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 522 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 532 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 542 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 552 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 563 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 573 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 583 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 593 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 604 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 614 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 624 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 634 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 645 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 655 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 665 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 675 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 686 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 696 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 706 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 716 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 727 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 737 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 747 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 757 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 768 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 778 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 788 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 798 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 808 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 819 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 829 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 839 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 849 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 860 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 870 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 880 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 890 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 901 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 911 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 921 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 931 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 942 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 952 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 962 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 972 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 983 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 993 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.0 MB 12.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.0 MB 12.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.0 MB 12.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.0 MB 12.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.0 MB 12.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.1 MB 12.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.1 MB 12.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.1 MB 12.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.1 MB 12.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.1 MB 12.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.1 MB 12.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.1 MB 12.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (2.7.1)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csu57YRLhUPe"
      },
      "source": [
        "# Imports dependencies\n",
        "from google.colab import files\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow.keras import regularizers\n",
        "from keras.models import Model\n",
        "import pathlib\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string\n",
        "import random\n",
        "from keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YmQuy8YpDbCg",
        "outputId": "43f470b5-d3b8-4b35-e1c3-9c72e64444bd"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjbfSUbohytB"
      },
      "source": [
        "# Loads in syllable data\n",
        "dataframe = pd.read_csv(\"/content/drive/MyDrive/syllabification-main/preprocessed.txt\",\n",
        "                        sep=\",\",\n",
        "                        encoding=\"ISO-8859-1\",\n",
        "                        names=[\"word\", \"label\"])\n",
        "# Necessary to specify str type for pandas columns\n",
        "dataframe = dataframe.astype(str)\n",
        "words = dataframe['word'].tolist()\n",
        "labels = dataframe['label'].tolist()\n",
        "# Converts each label to numpy array\n",
        "for i in range(0, len(labels)):\n",
        "    labels[i] = list(labels[i])\n",
        "    for j in range(0, len(labels[i])):\n",
        "        labels[i][j] = int(labels[i][j])\n",
        "for i in range(0, len(labels)):\n",
        "    labels[i] = np.array(labels[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gDS7CtLiAIj"
      },
      "source": [
        "# Vectorises syllable strings by treating each character as a token\n",
        "tokenizer = Tokenizer(char_level=True)\n",
        "tokenizer.fit_on_texts(words)\n",
        "words = tokenizer.texts_to_sequences(words)\n",
        "for i in range(0, len(words)):\n",
        "    words[i] = np.array(words[i], dtype=float)\n",
        "\n",
        "padded_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "    words, padding=\"post\", maxlen=15\n",
        ")\n",
        "padded_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "    labels, padding=\"post\", maxlen=15\n",
        ")\n",
        "\n",
        "# Normalisation\n",
        "maximum_token = 64\n",
        "for element in range(0, len(words)):\n",
        "    words[element] = words[element] / maximum_token"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgZKQGe1iFpj"
      },
      "source": [
        "# shuffles data\n",
        "seed = random.random()\n",
        "random.seed(seed)\n",
        "random.shuffle(padded_inputs)\n",
        "random.seed(seed)\n",
        "random.shuffle(padded_outputs)\n",
        "\n",
        "# splits into training and validation sets (80-20 split)\n",
        "validation_inputs = padded_inputs[-35497:]\n",
        "validation_outputs = padded_outputs[-35497:]\n",
        "padded_inputs = padded_inputs[:-35497]\n",
        "padded_outputs = padded_outputs[:-35497]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQezB-7cRHOC"
      },
      "source": [
        "# Custom loss function - mean of binary crossentropy and mean squared error\n",
        "def mean_weighted_bce_mse(y_true, y_prediction):\n",
        "    y_true = tf.cast(y_true, tf.float32)\n",
        "    y_prediction = tf.cast(y_prediction, tf.float32)\n",
        "\n",
        "    # Binary crossentropy with weighting\n",
        "    epsilon = 1e-6\n",
        "    positive_weight = 4.108897148948174\n",
        "    loss_positive = y_true * tf.math.log(y_prediction + epsilon)\n",
        "    loss_negative = (1 - y_true) * tf.math.log(1 - y_prediction + epsilon)\n",
        "    bce_loss = tf.math.reduce_mean(tf.math.negative(positive_weight * loss_positive + loss_negative))\n",
        "    \n",
        "    # Mean squared error\n",
        "    mse = tf.keras.losses.MeanSquaredError()\n",
        "    mse_loss = mse(y_true, y_prediction)\n",
        "\n",
        "    averaged_bce_mse = (bce_loss + mse_loss) / 2\n",
        "    return averaged_bce_mse"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Df2UpqpKl16x"
      },
      "source": [
        "def inception_module(inputs):\n",
        "    inception_branch_1 = tf.keras.layers.Conv1D(128, kernel_size=1, strides=2, activation=\"tanh\", activity_regularizer=tf.keras.regularizers.l2(1e-5))(inputs)\n",
        "    inception_branch_1 = tf.keras.layers.ZeroPadding1D(padding=(0, 15 - inception_branch_1.shape[1]))(inception_branch_1)\n",
        "\n",
        "    inception_branch_2 = tf.keras.layers.Conv1D(128, kernel_size=1, activation=\"tanh\", activity_regularizer=tf.keras.regularizers.l2(1e-5))(inputs)\n",
        "    inception_branch_2 = tf.keras.layers.Conv1D(128, kernel_size=3, strides=2, activation=\"tanh\", activity_regularizer=tf.keras.regularizers.l2(1e-5))(inception_branch_2)\n",
        "    inception_branch_2 = tf.keras.layers.ZeroPadding1D(padding=(0, 15 - inception_branch_2.shape[1]))(inception_branch_2)\n",
        "\n",
        "    inception_branch_3 = tf.keras.layers.AveragePooling1D(pool_size=3, strides=2)(inputs)\n",
        "    inception_branch_3 = tf.keras.layers.Conv1D(128, kernel_size=3, activation=\"tanh\", activity_regularizer=tf.keras.regularizers.l2(1e-5))(inception_branch_3)\n",
        "    inception_branch_3 = tf.keras.layers.ZeroPadding1D(padding=(0, 15 - inception_branch_3.shape[1]))(inception_branch_3)\n",
        "\n",
        "    inception_branch_4 = tf.keras.layers.Conv1D(128, kernel_size=1, activation=\"tanh\", activity_regularizer=tf.keras.regularizers.l2(1e-5))(inputs)\n",
        "    inception_branch_4 = tf.keras.layers.Conv1D(128, kernel_size=3, activation=\"tanh\", activity_regularizer=tf.keras.regularizers.l2(1e-5))(inception_branch_4)\n",
        "    inception_branch_4 = tf.keras.layers.Conv1D(128, kernel_size=3, strides=2, activation=\"tanh\", activity_regularizer=tf.keras.regularizers.l2(1e-5))(inception_branch_4)\n",
        "    inception_branch_4 = tf.keras.layers.ZeroPadding1D(padding=(0, 15 - inception_branch_4.shape[1]))(inception_branch_4)\n",
        "\n",
        "    inception_output = tf.keras.layers.concatenate([inception_branch_1, inception_branch_2, inception_branch_3, inception_branch_4, inputs])\n",
        "    return inception_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOip602ziQok"
      },
      "source": [
        "inputs = tf.keras.Input(shape=(15,))\n",
        "embedded_inputs = tf.keras.layers.Embedding(64, 256, mask_zero=True)(inputs)\n",
        "embedded_inputs = tf.keras.layers.Dropout(0.25)(embedded_inputs)\n",
        "\n",
        "x = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(256, return_sequences=True, dropout=0.1, activity_regularizer=tf.keras.regularizers.l2(1e-5)))(embedded_inputs)\n",
        "x = tf.keras.layers.concatenate([x, embedded_inputs])\n",
        "x = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(256, return_sequences=True, dropout=0.1, activity_regularizer=tf.keras.regularizers.l2(1e-5)))(x)\n",
        "x = tf.keras.layers.concatenate([x, embedded_inputs])\n",
        "x = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(256, return_sequences=True, activity_regularizer=tf.keras.regularizers.l2(1e-5)))(x)\n",
        "\n",
        "inception_output = inception_module(embedded_inputs)\n",
        "inception_output = tf.keras.layers.MaxPooling1D()(inception_output)\n",
        "inception_output =  tf.keras.layers.ZeroPadding1D(padding=(0, 15 - inception_output.shape[1]))(inception_output)\n",
        "inception_output = tf.keras.layers.Dropout(0.5)(inception_output)\n",
        "inception_output = inception_module(inception_output)\n",
        "inception_output = tf.keras.layers.MaxPooling1D()(inception_output)\n",
        "inception_output =  tf.keras.layers.ZeroPadding1D(padding=(0, 15 - inception_output.shape[1]))(inception_output)\n",
        "\n",
        "output = tf.keras.layers.concatenate([x, inception_output, embedded_inputs])\n",
        "output = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(256, activation=\"relu\"))(output)\n",
        "output = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(64, activation=\"relu\"))(output)\n",
        "output = tf.keras.layers.GlobalMaxPool1D()(output)\n",
        "output = tf.keras.layers.Dense(15, activation=\"sigmoid\")(output)\n",
        "\n",
        "metrics = [\"binary_accuracy\",\n",
        "           tfa.metrics.F1Score(num_classes=15, threshold=0.5),\n",
        "           tfa.metrics.HammingLoss(mode='multilabel', threshold=0.5),\n",
        "           tf.keras.metrics.Recall(),\n",
        "           tf.keras.metrics.Precision(),\n",
        "           tf.keras.metrics.AUC(multi_label=True, num_labels=15)]\n",
        "\n",
        "model = tf.keras.models.Model(inputs=inputs, outputs=output)\n",
        "model.compile(optimizer=\"adam\",\n",
        "              loss=mean_weighted_bce_mse,\n",
        "              metrics=metrics,\n",
        "              steps_per_execution=128)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rM_seEmJg7ux",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a74d6e33-ebcd-4fb3-c473-861ebd635e47"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 15)]         0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 15, 256)      16384       ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 15, 256)      0           ['embedding[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_4 (Conv1D)              (None, 15, 128)      32896       ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            " conv1d_1 (Conv1D)              (None, 15, 128)      32896       ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            " average_pooling1d (AveragePool  (None, 7, 256)      0           ['dropout[0][0]']                \n",
            " ing1D)                                                                                           \n",
            "                                                                                                  \n",
            " conv1d_5 (Conv1D)              (None, 13, 128)      49280       ['conv1d_4[0][0]']               \n",
            "                                                                                                  \n",
            " conv1d (Conv1D)                (None, 8, 128)       32896       ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            " conv1d_2 (Conv1D)              (None, 7, 128)       49280       ['conv1d_1[0][0]']               \n",
            "                                                                                                  \n",
            " conv1d_3 (Conv1D)              (None, 5, 128)       98432       ['average_pooling1d[0][0]']      \n",
            "                                                                                                  \n",
            " conv1d_6 (Conv1D)              (None, 6, 128)       49280       ['conv1d_5[0][0]']               \n",
            "                                                                                                  \n",
            " zero_padding1d (ZeroPadding1D)  (None, 15, 128)     0           ['conv1d[0][0]']                 \n",
            "                                                                                                  \n",
            " zero_padding1d_1 (ZeroPadding1  (None, 15, 128)     0           ['conv1d_2[0][0]']               \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " zero_padding1d_2 (ZeroPadding1  (None, 15, 128)     0           ['conv1d_3[0][0]']               \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " zero_padding1d_3 (ZeroPadding1  (None, 15, 128)     0           ['conv1d_6[0][0]']               \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 15, 768)      0           ['zero_padding1d[0][0]',         \n",
            "                                                                  'zero_padding1d_1[0][0]',       \n",
            "                                                                  'zero_padding1d_2[0][0]',       \n",
            "                                                                  'zero_padding1d_3[0][0]',       \n",
            "                                                                  'dropout[0][0]']                \n",
            "                                                                                                  \n",
            " max_pooling1d (MaxPooling1D)   (None, 7, 768)       0           ['concatenate_2[0][0]']          \n",
            "                                                                                                  \n",
            " zero_padding1d_4 (ZeroPadding1  (None, 15, 768)     0           ['max_pooling1d[0][0]']          \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 15, 768)      0           ['zero_padding1d_4[0][0]']       \n",
            "                                                                                                  \n",
            " conv1d_11 (Conv1D)             (None, 15, 128)      98432       ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_8 (Conv1D)              (None, 15, 128)      98432       ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            " average_pooling1d_1 (AveragePo  (None, 7, 768)      0           ['dropout_1[0][0]']              \n",
            " oling1D)                                                                                         \n",
            "                                                                                                  \n",
            " conv1d_12 (Conv1D)             (None, 13, 128)      49280       ['conv1d_11[0][0]']              \n",
            "                                                                                                  \n",
            " bidirectional (Bidirectional)  (None, 15, 512)      789504      ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            " conv1d_7 (Conv1D)              (None, 8, 128)       98432       ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_9 (Conv1D)              (None, 7, 128)       49280       ['conv1d_8[0][0]']               \n",
            "                                                                                                  \n",
            " conv1d_10 (Conv1D)             (None, 5, 128)       295040      ['average_pooling1d_1[0][0]']    \n",
            "                                                                                                  \n",
            " conv1d_13 (Conv1D)             (None, 6, 128)       49280       ['conv1d_12[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 15, 768)      0           ['bidirectional[0][0]',          \n",
            "                                                                  'dropout[0][0]']                \n",
            "                                                                                                  \n",
            " zero_padding1d_5 (ZeroPadding1  (None, 15, 128)     0           ['conv1d_7[0][0]']               \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " zero_padding1d_6 (ZeroPadding1  (None, 15, 128)     0           ['conv1d_9[0][0]']               \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " zero_padding1d_7 (ZeroPadding1  (None, 15, 128)     0           ['conv1d_10[0][0]']              \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " zero_padding1d_8 (ZeroPadding1  (None, 15, 128)     0           ['conv1d_13[0][0]']              \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " bidirectional_1 (Bidirectional  (None, 15, 512)     1575936     ['concatenate[0][0]']            \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate)    (None, 15, 1280)     0           ['zero_padding1d_5[0][0]',       \n",
            "                                                                  'zero_padding1d_6[0][0]',       \n",
            "                                                                  'zero_padding1d_7[0][0]',       \n",
            "                                                                  'zero_padding1d_8[0][0]',       \n",
            "                                                                  'dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 15, 768)      0           ['bidirectional_1[0][0]',        \n",
            "                                                                  'dropout[0][0]']                \n",
            "                                                                                                  \n",
            " max_pooling1d_1 (MaxPooling1D)  (None, 7, 1280)     0           ['concatenate_3[0][0]']          \n",
            "                                                                                                  \n",
            " bidirectional_2 (Bidirectional  (None, 15, 512)     1575936     ['concatenate_1[0][0]']          \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " zero_padding1d_9 (ZeroPadding1  (None, 15, 1280)    0           ['max_pooling1d_1[0][0]']        \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " concatenate_4 (Concatenate)    (None, 15, 2048)     0           ['bidirectional_2[0][0]',        \n",
            "                                                                  'zero_padding1d_9[0][0]',       \n",
            "                                                                  'dropout[0][0]']                \n",
            "                                                                                                  \n",
            " time_distributed (TimeDistribu  (None, 15, 256)     524544      ['concatenate_4[0][0]']          \n",
            " ted)                                                                                             \n",
            "                                                                                                  \n",
            " time_distributed_1 (TimeDistri  (None, 15, 64)      16448       ['time_distributed[0][0]']       \n",
            " buted)                                                                                           \n",
            "                                                                                                  \n",
            " global_max_pooling1d (GlobalMa  (None, 64)          0           ['time_distributed_1[0][0]']     \n",
            " xPooling1D)                                                                                      \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 15)           975         ['global_max_pooling1d[0][0]']   \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 5,582,863\n",
            "Trainable params: 5,582,863\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_CQt-B_ibtm",
        "outputId": "b829ab16-240f-4508-a3d7-0d723710bb0c"
      },
      "source": [
        "history = model.fit(padded_inputs,\n",
        "                    padded_outputs,\n",
        "                    validation_data=(validation_inputs, validation_outputs),\n",
        "                    epochs=50,\n",
        "                    batch_size=64)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "2219/2219 [==============================] - 289s 130ms/step - loss: 0.1719 - binary_accuracy: 0.9236 - f1_score: 0.6357 - hamming_loss: 0.0764 - recall: 0.8994 - precision: 0.6538 - auc: 0.8976 - val_loss: 0.1338 - val_binary_accuracy: 0.9452 - val_f1_score: 0.7299 - val_hamming_loss: 0.0548 - val_recall: 0.9397 - val_precision: 0.7519 - val_auc: 0.9162\n",
            "Epoch 2/50\n",
            "2219/2219 [==============================] - 207s 93ms/step - loss: 0.1036 - binary_accuracy: 0.9613 - f1_score: 0.7740 - hamming_loss: 0.0387 - recall: 0.9440 - precision: 0.8000 - auc: 0.9202 - val_loss: 0.0996 - val_binary_accuracy: 0.9637 - val_f1_score: 0.7981 - val_hamming_loss: 0.0363 - val_recall: 0.9544 - val_precision: 0.8269 - val_auc: 0.9244\n",
            "Epoch 3/50\n",
            "2219/2219 [==============================] - 207s 93ms/step - loss: 0.0761 - binary_accuracy: 0.9738 - f1_score: 0.8206 - hamming_loss: 0.0262 - recall: 0.9613 - precision: 0.8578 - auc: 0.9268 - val_loss: 0.0873 - val_binary_accuracy: 0.9707 - val_f1_score: 0.8205 - val_hamming_loss: 0.0293 - val_recall: 0.9597 - val_precision: 0.8589 - val_auc: 0.9264\n",
            "Epoch 4/50\n",
            "2219/2219 [==============================] - 207s 93ms/step - loss: 0.0589 - binary_accuracy: 0.9812 - f1_score: 0.8461 - hamming_loss: 0.0188 - recall: 0.9721 - precision: 0.8947 - auc: 0.9287 - val_loss: 0.0808 - val_binary_accuracy: 0.9759 - val_f1_score: 0.8344 - val_hamming_loss: 0.0241 - val_recall: 0.9610 - val_precision: 0.8857 - val_auc: 0.9272\n",
            "Epoch 5/50\n",
            "2219/2219 [==============================] - 205s 92ms/step - loss: 0.0482 - binary_accuracy: 0.9855 - f1_score: 0.8647 - hamming_loss: 0.0145 - recall: 0.9784 - precision: 0.9173 - auc: 0.9305 - val_loss: 0.0817 - val_binary_accuracy: 0.9770 - val_f1_score: 0.8381 - val_hamming_loss: 0.0230 - val_recall: 0.9587 - val_precision: 0.8938 - val_auc: 0.9266\n",
            "Epoch 6/50\n",
            "2219/2219 [==============================] - 203s 92ms/step - loss: 0.0413 - binary_accuracy: 0.9881 - f1_score: 0.8739 - hamming_loss: 0.0119 - recall: 0.9824 - precision: 0.9317 - auc: 0.9316 - val_loss: 0.0829 - val_binary_accuracy: 0.9792 - val_f1_score: 0.8551 - val_hamming_loss: 0.0208 - val_recall: 0.9591 - val_precision: 0.9057 - val_auc: 0.9263\n",
            "Epoch 7/50\n",
            "2219/2219 [==============================] - 204s 92ms/step - loss: 0.0365 - binary_accuracy: 0.9899 - f1_score: 0.8785 - hamming_loss: 0.0101 - recall: 0.9850 - precision: 0.9411 - auc: 0.9319 - val_loss: 0.0854 - val_binary_accuracy: 0.9800 - val_f1_score: 0.8418 - val_hamming_loss: 0.0200 - val_recall: 0.9571 - val_precision: 0.9122 - val_auc: 0.9260\n",
            "Epoch 8/50\n",
            "2219/2219 [==============================] - 204s 92ms/step - loss: 0.0339 - binary_accuracy: 0.9909 - f1_score: 0.8847 - hamming_loss: 0.0091 - recall: 0.9864 - precision: 0.9471 - auc: 0.9315 - val_loss: 0.0836 - val_binary_accuracy: 0.9794 - val_f1_score: 0.8496 - val_hamming_loss: 0.0206 - val_recall: 0.9613 - val_precision: 0.9052 - val_auc: 0.9259\n",
            "Epoch 9/50\n",
            "2219/2219 [==============================] - 202s 91ms/step - loss: 0.0316 - binary_accuracy: 0.9919 - f1_score: 0.8883 - hamming_loss: 0.0081 - recall: 0.9879 - precision: 0.9528 - auc: 0.9322 - val_loss: 0.0827 - val_binary_accuracy: 0.9816 - val_f1_score: 0.8525 - val_hamming_loss: 0.0184 - val_recall: 0.9606 - val_precision: 0.9189 - val_auc: 0.9257\n",
            "Epoch 10/50\n",
            "2219/2219 [==============================] - 204s 92ms/step - loss: 0.0290 - binary_accuracy: 0.9926 - f1_score: 0.8918 - hamming_loss: 0.0074 - recall: 0.9890 - precision: 0.9566 - auc: 0.9314 - val_loss: 0.0806 - val_binary_accuracy: 0.9817 - val_f1_score: 0.8512 - val_hamming_loss: 0.0183 - val_recall: 0.9645 - val_precision: 0.9161 - val_auc: 0.9229\n",
            "Epoch 11/50\n",
            "2219/2219 [==============================] - 205s 92ms/step - loss: 0.0275 - binary_accuracy: 0.9931 - f1_score: 0.8952 - hamming_loss: 0.0069 - recall: 0.9899 - precision: 0.9595 - auc: 0.9320 - val_loss: 0.0879 - val_binary_accuracy: 0.9811 - val_f1_score: 0.8557 - val_hamming_loss: 0.0189 - val_recall: 0.9631 - val_precision: 0.9139 - val_auc: 0.9236\n",
            "Epoch 12/50\n",
            "2219/2219 [==============================] - 205s 92ms/step - loss: 0.0271 - binary_accuracy: 0.9933 - f1_score: 0.8949 - hamming_loss: 0.0067 - recall: 0.9900 - precision: 0.9604 - auc: 0.9319 - val_loss: 0.0883 - val_binary_accuracy: 0.9831 - val_f1_score: 0.8653 - val_hamming_loss: 0.0169 - val_recall: 0.9583 - val_precision: 0.9294 - val_auc: 0.9246\n",
            "Epoch 13/50\n",
            "2219/2219 [==============================] - 203s 92ms/step - loss: 0.0255 - binary_accuracy: 0.9938 - f1_score: 0.9009 - hamming_loss: 0.0062 - recall: 0.9908 - precision: 0.9633 - auc: 0.9326 - val_loss: 0.0809 - val_binary_accuracy: 0.9829 - val_f1_score: 0.8551 - val_hamming_loss: 0.0171 - val_recall: 0.9640 - val_precision: 0.9239 - val_auc: 0.9242\n",
            "Epoch 14/50\n",
            "2219/2219 [==============================] - 203s 91ms/step - loss: 0.0254 - binary_accuracy: 0.9938 - f1_score: 0.8996 - hamming_loss: 0.0062 - recall: 0.9908 - precision: 0.9637 - auc: 0.9320 - val_loss: 0.0844 - val_binary_accuracy: 0.9831 - val_f1_score: 0.8642 - val_hamming_loss: 0.0169 - val_recall: 0.9636 - val_precision: 0.9252 - val_auc: 0.9202\n",
            "Epoch 15/50\n",
            "2219/2219 [==============================] - 202s 91ms/step - loss: 0.0248 - binary_accuracy: 0.9940 - f1_score: 0.9055 - hamming_loss: 0.0060 - recall: 0.9911 - precision: 0.9644 - auc: 0.9320 - val_loss: 0.0864 - val_binary_accuracy: 0.9827 - val_f1_score: 0.8582 - val_hamming_loss: 0.0173 - val_recall: 0.9623 - val_precision: 0.9237 - val_auc: 0.9234\n",
            "Epoch 16/50\n",
            "2219/2219 [==============================] - 203s 91ms/step - loss: 0.0237 - binary_accuracy: 0.9944 - f1_score: 0.9038 - hamming_loss: 0.0056 - recall: 0.9916 - precision: 0.9666 - auc: 0.9321 - val_loss: 0.0872 - val_binary_accuracy: 0.9830 - val_f1_score: 0.8648 - val_hamming_loss: 0.0170 - val_recall: 0.9627 - val_precision: 0.9256 - val_auc: 0.9232\n",
            "Epoch 17/50\n",
            "2219/2219 [==============================] - 204s 92ms/step - loss: 0.0230 - binary_accuracy: 0.9945 - f1_score: 0.9065 - hamming_loss: 0.0055 - recall: 0.9921 - precision: 0.9675 - auc: 0.9321 - val_loss: 0.0857 - val_binary_accuracy: 0.9834 - val_f1_score: 0.8728 - val_hamming_loss: 0.0166 - val_recall: 0.9616 - val_precision: 0.9290 - val_auc: 0.9204\n",
            "Epoch 18/50\n",
            "2219/2219 [==============================] - 201s 91ms/step - loss: 0.0231 - binary_accuracy: 0.9945 - f1_score: 0.9079 - hamming_loss: 0.0055 - recall: 0.9920 - precision: 0.9671 - auc: 0.9326 - val_loss: 0.0835 - val_binary_accuracy: 0.9835 - val_f1_score: 0.8622 - val_hamming_loss: 0.0165 - val_recall: 0.9621 - val_precision: 0.9292 - val_auc: 0.9242\n",
            "Epoch 19/50\n",
            "2219/2219 [==============================] - 202s 91ms/step - loss: 0.0224 - binary_accuracy: 0.9947 - f1_score: 0.9075 - hamming_loss: 0.0053 - recall: 0.9922 - precision: 0.9688 - auc: 0.9327 - val_loss: 0.0863 - val_binary_accuracy: 0.9846 - val_f1_score: 0.8710 - val_hamming_loss: 0.0154 - val_recall: 0.9644 - val_precision: 0.9335 - val_auc: 0.9180\n",
            "Epoch 20/50\n",
            "2219/2219 [==============================] - 201s 91ms/step - loss: 0.0222 - binary_accuracy: 0.9947 - f1_score: 0.9049 - hamming_loss: 0.0053 - recall: 0.9923 - precision: 0.9686 - auc: 0.9326 - val_loss: 0.0901 - val_binary_accuracy: 0.9835 - val_f1_score: 0.8649 - val_hamming_loss: 0.0165 - val_recall: 0.9604 - val_precision: 0.9303 - val_auc: 0.9201\n",
            "Epoch 21/50\n",
            "2219/2219 [==============================] - 202s 91ms/step - loss: 0.0212 - binary_accuracy: 0.9950 - f1_score: 0.9082 - hamming_loss: 0.0050 - recall: 0.9927 - precision: 0.9701 - auc: 0.9327 - val_loss: 0.0922 - val_binary_accuracy: 0.9835 - val_f1_score: 0.8522 - val_hamming_loss: 0.0165 - val_recall: 0.9611 - val_precision: 0.9296 - val_auc: 0.9166\n",
            "Epoch 22/50\n",
            "2219/2219 [==============================] - 208s 94ms/step - loss: 0.0219 - binary_accuracy: 0.9947 - f1_score: 0.9058 - hamming_loss: 0.0052 - recall: 0.9924 - precision: 0.9688 - auc: 0.9327 - val_loss: 0.0890 - val_binary_accuracy: 0.9844 - val_f1_score: 0.8776 - val_hamming_loss: 0.0156 - val_recall: 0.9627 - val_precision: 0.9337 - val_auc: 0.9226\n",
            "Epoch 23/50\n",
            "2219/2219 [==============================] - 201s 90ms/step - loss: 0.0200 - binary_accuracy: 0.9953 - f1_score: 0.9089 - hamming_loss: 0.0047 - recall: 0.9932 - precision: 0.9722 - auc: 0.9327 - val_loss: 0.0894 - val_binary_accuracy: 0.9832 - val_f1_score: 0.8667 - val_hamming_loss: 0.0168 - val_recall: 0.9629 - val_precision: 0.9265 - val_auc: 0.9217\n",
            "Epoch 24/50\n",
            "2219/2219 [==============================] - 201s 90ms/step - loss: 0.0203 - binary_accuracy: 0.9952 - f1_score: 0.9124 - hamming_loss: 0.0048 - recall: 0.9931 - precision: 0.9712 - auc: 0.9327 - val_loss: 0.0906 - val_binary_accuracy: 0.9839 - val_f1_score: 0.8651 - val_hamming_loss: 0.0161 - val_recall: 0.9597 - val_precision: 0.9336 - val_auc: 0.9197\n",
            "Epoch 25/50\n",
            "2219/2219 [==============================] - 201s 90ms/step - loss: 0.0206 - binary_accuracy: 0.9951 - f1_score: 0.9047 - hamming_loss: 0.0049 - recall: 0.9930 - precision: 0.9710 - auc: 0.9322 - val_loss: 0.0968 - val_binary_accuracy: 0.9835 - val_f1_score: 0.8541 - val_hamming_loss: 0.0165 - val_recall: 0.9577 - val_precision: 0.9329 - val_auc: 0.9223\n",
            "Epoch 26/50\n",
            "2219/2219 [==============================] - 200s 90ms/step - loss: 0.0208 - binary_accuracy: 0.9950 - f1_score: 0.9085 - hamming_loss: 0.0050 - recall: 0.9929 - precision: 0.9703 - auc: 0.9327 - val_loss: 0.0921 - val_binary_accuracy: 0.9838 - val_f1_score: 0.8709 - val_hamming_loss: 0.0162 - val_recall: 0.9616 - val_precision: 0.9309 - val_auc: 0.9206\n",
            "Epoch 27/50\n",
            "2219/2219 [==============================] - 200s 90ms/step - loss: 0.0189 - binary_accuracy: 0.9956 - f1_score: 0.9140 - hamming_loss: 0.0044 - recall: 0.9937 - precision: 0.9734 - auc: 0.9323 - val_loss: 0.0869 - val_binary_accuracy: 0.9848 - val_f1_score: 0.8773 - val_hamming_loss: 0.0152 - val_recall: 0.9623 - val_precision: 0.9369 - val_auc: 0.9156\n",
            "Epoch 28/50\n",
            "2219/2219 [==============================] - 200s 90ms/step - loss: 0.0192 - binary_accuracy: 0.9955 - f1_score: 0.9140 - hamming_loss: 0.0045 - recall: 0.9937 - precision: 0.9729 - auc: 0.9323 - val_loss: 0.0899 - val_binary_accuracy: 0.9835 - val_f1_score: 0.8714 - val_hamming_loss: 0.0165 - val_recall: 0.9644 - val_precision: 0.9272 - val_auc: 0.9224\n",
            "Epoch 29/50\n",
            "2219/2219 [==============================] - 200s 90ms/step - loss: 0.0199 - binary_accuracy: 0.9952 - f1_score: 0.9106 - hamming_loss: 0.0048 - recall: 0.9931 - precision: 0.9715 - auc: 0.9327 - val_loss: 0.0947 - val_binary_accuracy: 0.9844 - val_f1_score: 0.8749 - val_hamming_loss: 0.0156 - val_recall: 0.9600 - val_precision: 0.9363 - val_auc: 0.9230\n",
            "Epoch 30/50\n",
            "2219/2219 [==============================] - 201s 91ms/step - loss: 0.0187 - binary_accuracy: 0.9956 - f1_score: 0.9138 - hamming_loss: 0.0044 - recall: 0.9937 - precision: 0.9735 - auc: 0.9328 - val_loss: 0.0964 - val_binary_accuracy: 0.9839 - val_f1_score: 0.8707 - val_hamming_loss: 0.0161 - val_recall: 0.9604 - val_precision: 0.9330 - val_auc: 0.9203\n",
            "Epoch 31/50\n",
            "2219/2219 [==============================] - 201s 91ms/step - loss: 0.0190 - binary_accuracy: 0.9955 - f1_score: 0.9125 - hamming_loss: 0.0045 - recall: 0.9939 - precision: 0.9728 - auc: 0.9323 - val_loss: 0.0916 - val_binary_accuracy: 0.9840 - val_f1_score: 0.8717 - val_hamming_loss: 0.0160 - val_recall: 0.9596 - val_precision: 0.9342 - val_auc: 0.9181\n",
            "Epoch 32/50\n",
            "2219/2219 [==============================] - 202s 91ms/step - loss: 0.0182 - binary_accuracy: 0.9957 - f1_score: 0.9125 - hamming_loss: 0.0043 - recall: 0.9939 - precision: 0.9742 - auc: 0.9329 - val_loss: 0.0884 - val_binary_accuracy: 0.9846 - val_f1_score: 0.8760 - val_hamming_loss: 0.0154 - val_recall: 0.9622 - val_precision: 0.9356 - val_auc: 0.9198\n",
            "Epoch 33/50\n",
            "2219/2219 [==============================] - 201s 91ms/step - loss: 0.0185 - binary_accuracy: 0.9956 - f1_score: 0.9110 - hamming_loss: 0.0044 - recall: 0.9937 - precision: 0.9736 - auc: 0.9323 - val_loss: 0.0918 - val_binary_accuracy: 0.9849 - val_f1_score: 0.8746 - val_hamming_loss: 0.0151 - val_recall: 0.9609 - val_precision: 0.9383 - val_auc: 0.9180\n",
            "Epoch 34/50\n",
            "2219/2219 [==============================] - 203s 91ms/step - loss: 0.0181 - binary_accuracy: 0.9957 - f1_score: 0.9110 - hamming_loss: 0.0043 - recall: 0.9942 - precision: 0.9742 - auc: 0.9318 - val_loss: 0.0930 - val_binary_accuracy: 0.9846 - val_f1_score: 0.8782 - val_hamming_loss: 0.0154 - val_recall: 0.9626 - val_precision: 0.9353 - val_auc: 0.9203\n",
            "Epoch 35/50\n",
            "2219/2219 [==============================] - 201s 91ms/step - loss: 0.0190 - binary_accuracy: 0.9954 - f1_score: 0.9160 - hamming_loss: 0.0046 - recall: 0.9936 - precision: 0.9726 - auc: 0.9322 - val_loss: 0.0906 - val_binary_accuracy: 0.9847 - val_f1_score: 0.8805 - val_hamming_loss: 0.0153 - val_recall: 0.9600 - val_precision: 0.9379 - val_auc: 0.9211\n",
            "Epoch 36/50\n",
            "2219/2219 [==============================] - 201s 91ms/step - loss: 0.0181 - binary_accuracy: 0.9957 - f1_score: 0.9138 - hamming_loss: 0.0043 - recall: 0.9940 - precision: 0.9741 - auc: 0.9317 - val_loss: 0.0967 - val_binary_accuracy: 0.9837 - val_f1_score: 0.8751 - val_hamming_loss: 0.0163 - val_recall: 0.9595 - val_precision: 0.9326 - val_auc: 0.9153\n",
            "Epoch 37/50\n",
            "2219/2219 [==============================] - 200s 90ms/step - loss: 0.0180 - binary_accuracy: 0.9957 - f1_score: 0.9127 - hamming_loss: 0.0043 - recall: 0.9941 - precision: 0.9742 - auc: 0.9328 - val_loss: 0.0938 - val_binary_accuracy: 0.9842 - val_f1_score: 0.8679 - val_hamming_loss: 0.0158 - val_recall: 0.9616 - val_precision: 0.9334 - val_auc: 0.9204\n",
            "Epoch 38/50\n",
            "2219/2219 [==============================] - 200s 90ms/step - loss: 0.0175 - binary_accuracy: 0.9958 - f1_score: 0.9132 - hamming_loss: 0.0042 - recall: 0.9942 - precision: 0.9747 - auc: 0.9328 - val_loss: 0.0967 - val_binary_accuracy: 0.9849 - val_f1_score: 0.8774 - val_hamming_loss: 0.0151 - val_recall: 0.9594 - val_precision: 0.9397 - val_auc: 0.9169\n",
            "Epoch 39/50\n",
            "2219/2219 [==============================] - 199s 90ms/step - loss: 0.0187 - binary_accuracy: 0.9955 - f1_score: 0.9087 - hamming_loss: 0.0045 - recall: 0.9937 - precision: 0.9731 - auc: 0.9323 - val_loss: 0.0937 - val_binary_accuracy: 0.9839 - val_f1_score: 0.8720 - val_hamming_loss: 0.0161 - val_recall: 0.9607 - val_precision: 0.9324 - val_auc: 0.9157\n",
            "Epoch 40/50\n",
            "2219/2219 [==============================] - 199s 90ms/step - loss: 0.0167 - binary_accuracy: 0.9961 - f1_score: 0.9137 - hamming_loss: 0.0039 - recall: 0.9945 - precision: 0.9764 - auc: 0.9324 - val_loss: 0.0911 - val_binary_accuracy: 0.9839 - val_f1_score: 0.8760 - val_hamming_loss: 0.0161 - val_recall: 0.9632 - val_precision: 0.9305 - val_auc: 0.9211\n",
            "Epoch 41/50\n",
            "2219/2219 [==============================] - 199s 90ms/step - loss: 0.0168 - binary_accuracy: 0.9960 - f1_score: 0.9171 - hamming_loss: 0.0040 - recall: 0.9946 - precision: 0.9757 - auc: 0.9328 - val_loss: 0.0970 - val_binary_accuracy: 0.9840 - val_f1_score: 0.8726 - val_hamming_loss: 0.0160 - val_recall: 0.9609 - val_precision: 0.9330 - val_auc: 0.9186\n",
            "Epoch 42/50\n",
            "2219/2219 [==============================] - 200s 90ms/step - loss: 0.0172 - binary_accuracy: 0.9959 - f1_score: 0.9136 - hamming_loss: 0.0041 - recall: 0.9945 - precision: 0.9752 - auc: 0.9323 - val_loss: 0.0911 - val_binary_accuracy: 0.9849 - val_f1_score: 0.8744 - val_hamming_loss: 0.0151 - val_recall: 0.9611 - val_precision: 0.9384 - val_auc: 0.9137\n",
            "Epoch 43/50\n",
            "2219/2219 [==============================] - 200s 90ms/step - loss: 0.0172 - binary_accuracy: 0.9958 - f1_score: 0.9143 - hamming_loss: 0.0042 - recall: 0.9943 - precision: 0.9748 - auc: 0.9324 - val_loss: 0.0936 - val_binary_accuracy: 0.9848 - val_f1_score: 0.8783 - val_hamming_loss: 0.0153 - val_recall: 0.9609 - val_precision: 0.9376 - val_auc: 0.9210\n",
            "Epoch 44/50\n",
            "2219/2219 [==============================] - 199s 89ms/step - loss: 0.0163 - binary_accuracy: 0.9961 - f1_score: 0.9139 - hamming_loss: 0.0039 - recall: 0.9947 - precision: 0.9761 - auc: 0.9318 - val_loss: 0.0957 - val_binary_accuracy: 0.9836 - val_f1_score: 0.8694 - val_hamming_loss: 0.0164 - val_recall: 0.9617 - val_precision: 0.9301 - val_auc: 0.9197\n",
            "Epoch 45/50\n",
            "2219/2219 [==============================] - 199s 90ms/step - loss: 0.0172 - binary_accuracy: 0.9958 - f1_score: 0.9127 - hamming_loss: 0.0042 - recall: 0.9944 - precision: 0.9746 - auc: 0.9318 - val_loss: 0.0970 - val_binary_accuracy: 0.9846 - val_f1_score: 0.8717 - val_hamming_loss: 0.0154 - val_recall: 0.9606 - val_precision: 0.9372 - val_auc: 0.9188\n",
            "Epoch 46/50\n",
            "2219/2219 [==============================] - 200s 90ms/step - loss: 0.0163 - binary_accuracy: 0.9961 - f1_score: 0.9106 - hamming_loss: 0.0039 - recall: 0.9946 - precision: 0.9765 - auc: 0.9317 - val_loss: 0.1006 - val_binary_accuracy: 0.9844 - val_f1_score: 0.8767 - val_hamming_loss: 0.0156 - val_recall: 0.9597 - val_precision: 0.9367 - val_auc: 0.9199\n",
            "Epoch 47/50\n",
            "2219/2219 [==============================] - 199s 90ms/step - loss: 0.0160 - binary_accuracy: 0.9961 - f1_score: 0.9159 - hamming_loss: 0.0039 - recall: 0.9948 - precision: 0.9764 - auc: 0.9324 - val_loss: 0.0963 - val_binary_accuracy: 0.9851 - val_f1_score: 0.8779 - val_hamming_loss: 0.0149 - val_recall: 0.9610 - val_precision: 0.9396 - val_auc: 0.9182\n",
            "Epoch 48/50\n",
            "2219/2219 [==============================] - 199s 90ms/step - loss: 0.0168 - binary_accuracy: 0.9959 - f1_score: 0.9151 - hamming_loss: 0.0041 - recall: 0.9944 - precision: 0.9748 - auc: 0.9323 - val_loss: 0.0930 - val_binary_accuracy: 0.9850 - val_f1_score: 0.8755 - val_hamming_loss: 0.0150 - val_recall: 0.9638 - val_precision: 0.9369 - val_auc: 0.9224\n",
            "Epoch 49/50\n",
            "2219/2219 [==============================] - 198s 89ms/step - loss: 0.0158 - binary_accuracy: 0.9962 - f1_score: 0.9151 - hamming_loss: 0.0038 - recall: 0.9949 - precision: 0.9766 - auc: 0.9319 - val_loss: 0.0948 - val_binary_accuracy: 0.9847 - val_f1_score: 0.8777 - val_hamming_loss: 0.0153 - val_recall: 0.9602 - val_precision: 0.9379 - val_auc: 0.9222\n",
            "Epoch 50/50\n",
            "2219/2219 [==============================] - 200s 90ms/step - loss: 0.0151 - binary_accuracy: 0.9963 - f1_score: 0.9170 - hamming_loss: 0.0037 - recall: 0.9951 - precision: 0.9775 - auc: 0.9320 - val_loss: 0.0966 - val_binary_accuracy: 0.9850 - val_f1_score: 0.8733 - val_hamming_loss: 0.0150 - val_recall: 0.9598 - val_precision: 0.9398 - val_auc: 0.9185\n"
          ]
        }
      ]
    }
  ]
}